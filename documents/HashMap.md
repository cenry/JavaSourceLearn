# HashMap中文文档

## 文档翻译

> 翻译约定
>
> capacity -- 容量
>
> bucket -- 存储桶
>
> hash table -- 哈希表
>
> map -- 映射
>
> mapping -- 映射关系
>
> rehash -- 重新进行哈希计算
>
> fail-fast -- 快速失败

基于哈希表的`Map`接口实现。此实现提供所有可选的映射操作，并允许`null` 值和`null` 键（`HashMap`类大致等同于`Hashtable`，只是`HashMap`不同步并且允许空值）。`HashMap`不保证元素的顺序不会变化。

假设哈希函数在存储桶之间完全均匀地分散元素，那么`get`和`put`的时间复杂度为O(1)。

`HashMap`元素迭代时间与“容量”（bucket的数量）加上其大小（键值映射的数量）成正比。如果迭代性能很重要的话，不要设置太高的初始容量（或者太低的负载因子）。

`HashMap`有两个影响性能的参数：初始容量和负载因子。容量是哈希表中的存储桶数，初始容量只是创建哈希表时的容量。负载因子是度量哈希表何时进行自动扩容的标尺。当哈希表中的条目数超过负载因子和当前容量的乘积时，哈希表将进行rehash（即重建内部数据结构），并使存储桶数量变为原来的两倍。

一般来说，默认负载因子（.75）在时间和空间成本之间提供了一个很好的折衷。较高的值会减少空间开销，但会增加查找成本（因为空间越小越容易产生哈希冲突，导致一个存储桶中存放很多相同哈希值的元素）。在设置初始容量时，应考虑map中的预期条目数及其负载因子，以尽量减少rehash次数。如果预计要在`HashMap`中存放很多元素，最好把初始容量定得足够大，这样它的性能会好过反复扩容。

使用具有相同`hashCode()`的多个键必定会降低任何哈希表的性能。为了改善这种情况，当键是可比较的时候（实现`Comparable`接口），这个类可以使用键之间的比较顺序来帮助打破联系。

请注意，`HashMap`是不同步的。如果多个线程同时访问一个`HashMap`，并且至少有一个线程在结构上修改了该映射，则必须在外部对其进行同步。（结构修改是添加或删除一个或多个映射关系的任何操作；仅更改与实例已包含的键相关联的值不是结构修改。）这通常通过在自然封装映射的某个对象上进行同步来完成。如果不存在此类对象，则应使用`Collections.synchronizedMap`方法“包装”映射。最好在创建时执行此操作，以防止意外地对映射进行非同步访问：

```java
Map m = Collections.synchronizedMap(new HashMap(...));
```

这个类的所有“集合查看方法”返回的迭代器都是快速失败的：如果在迭代器创建后的任何时候对映射进行了结构修改（除了通过迭代器自己的remove方法之外），迭代器将抛出一个`ConcurrentModificationException`。因此，在面对并发修改时，迭代器会即刻失败，以绝后患。

注意，不能依赖于这种快速失败机制来编程，因为它不是100%可靠的（不一定会在应该抛出异常的时候抛出异常），而仅仅是一种错误检测的手段。



实现说明

当一个存储桶变得太大时，它们会被转换成`TreeNode`（`HashMap`的内部类），元素的结构与`java.util.TreeMap`（红黑树）中的元素相似。大多数方法会像使用普通元素那样使用这些元素，但在适当的时候会用TreeNode专用的方法处理它们（只是通过`instanceof`检查节点的类型）。

这个红黑树可以正常遍历和使用，且在元素数量多的情况下有更快的查找速度。不过，大多数情况下，因为一个存储桶中的元素不会那么多，在一些方法中`TreeNode`的检查会被延迟。

树结构容器（其元素均为`TreeNode`）主要按hashCode排序，但如果两个元素实现了相同的`Comparable<T>`且互相可以比较，那么`CompareTo`方法比较的结果会被用于排序。（我们保守地通过反射来检查泛型类型，以验证这一点——请参阅方法`comparableClassFor`）。

“key之间的哈希值区别较大”、“key之间是可排序的”这两个条件只要满足其中一个，那么树结构查找的复杂度是比较可观的，时间复杂度最差是O(log n)。如果意外地或恶意地使用它，导致key之间的哈希值几乎都相同，但只要key之间仍然是可排序的，性能就不会下降得太厉害。如果这两个条件都不满足，那么引入树结构反而会使性能下降，在时间消耗和空间消耗上都会达到原来的2倍，不过话说回来，这种极端情况下即使不用树结构，性能也够差了。

由于`TreeNode`的大小大约是常规节点的两倍，因此我们仅在容器包含足够的节点以保证使用时才使用它们（请参见`TREEIFY_THRESHOLD`）。当元素数量变少（由于移除或调整大小）时，树形结构会被转回链式结构。在使用哈希值分布良好的哈希函数时，很少使用树形结构。

理想情况下，进来一个元素，计算哈希值后，命中某个存储桶的概率遵循泊松分布，泊松分布公式如下：

```
P\{X = k\} = (λ ^ k) * (e ^ (-λ)) / (k!)
```
公式的意思是：假设在单位时间内某一件事情平均会发生 λ 次，那么他会发生 k 次的概率是这么多。

当调整阈值为默认大小0.75时，λ 约为0.5，代入泊松公式，一个存储桶中有 k 个元素的概率是：

0：0.60653066

1：0.30326533

2：0.07581633

3：0.01263606

4：0.00157952

5：0.00015795

6：0.00001316

7：0.00000094

8：0.00000006

更多：不到千万分之一

可以看到，在默认阈值下，单位时间内一个存储桶中的元素超过8个的概率极小，所以0.75这个负载因子是合理的。

树结构的根节点通常是它的第一个节点，但有时候（目前只有`Iterator.remove`）根节点可能在其他地方，且可以在`TreeNode.root()`方法之后恢复。

在适当的时候，一些内部方法都接受哈希值作为参数，这样在它们相互调用时不用重新去计算哈希值。大多数内部方法也接受一个“tab”参数，通常是当前表，但在调整大小或转换时可能是新的表或旧的表。

当存储桶被树结构化、拆分或从树结构转回时，我们将它们保持其元素的相对访问/遍历顺序（即`field Node.next`），以保持它的局部结构，并且对调用`iterator.remove`的拆分和遍历操作起到一点简化作用。在元素插入时，会以类比较和哈希值为依据，重新调整结构以保持整体的顺序。

由于`LinkedHashMap`子类的存在，普通模式和树模式之间的使用和转换非常复杂。关于插入、删除和访问时调用的钩子方法，请参见下面的内容（指类定义中与`LinkedHashMap`相关的内容），这些方法让`LinkedHashMap`有独立的一套内部机制。

基于SSA的并发编程风格有助于避免在所有扭曲指针操作中出现混叠错误。

## 附录一

`resize()`扩容方法中，从原table把元素移动到新table时直接使用了这个结论：

```java
// 其中j是该链表在原table中的位置，oldCap是原容量，newCap是新容量，e.hash是节点Node<K,V>中存的hash值
// 等价关系是从源码中提炼出来的，并非原表达式
((e.hash & oldCap) == 0) => newTab[j]
((e.hash & oldCap) != 0) => newTab[j + oldCap]
```

HashMap中每个元素的哈希值的计算方式是：

```java
int h = key.hashCode(); // 调用的是Object.hashCode()
int hash = (table.length - 1) & (h ^ (h >>> 16));
// 先声明一下`static class Node<K,V> implements Map.Entry<K,V>`这个内部类中的`final int hash`字段存放的是(h ^ (h >>> 16))而不是与table长度有关的这个hash。
```

现假设原容量是16，扩容后容量为32。

e.hash = h，oldCap = 16，newCap = 32

现在`e.hash = h`，`oldCap = 16`，`newCap = 32`

> 无关的位都以\*代替。

首先是`(e.hash & oldCap) == 0`的情况，扩容后和扩容前的hash值是一样的，所以数组索引不变。

```
e.hash           **** **** **** **** **** **** 0010 1001

oldCap = 16      0000 0000 0000 0000 0000 0000 0001 0000
e.hash & oldCap  0000 0000 0000 0000 0000 0000 0000 0000 => 判断条件 == 0
15               0000 0000 0000 0000 0000 0000 0000 1111
e.hash & 15      0000 0000 0000 0000 0000 0000 0000 1001 => 原最终hash值

newCap = 32      0000 0000 0000 0000 0000 0000 0010 0000
31               0000 0000 0000 0000 0000 0000 0001 1111
e.hash & 31      0000 0000 0000 0000 0000 0000 0000 1001 => 扩容后的最终hash值
```

然后是`(e.hash & oldCap) != 0`的情况，扩容后hash值会变大，增量和oldCap等值，数组索引要加oldCap。

```
e.hash           **** **** **** **** **** **** 0011 1001

oldCap = 16      0000 0000 0000 0000 0000 0000 0001 0000
e.hash & oldCap  0000 0000 0000 0000 0000 0000 0001 0000 => 判断条件 != 0
15               0000 0000 0000 0000 0000 0000 0000 1111
e.hash & 15      0000 0000 0000 0000 0000 0000 0000 1001 => 原最终hash值

newCap = 32      0000 0000 0000 0000 0000 0000 0010 0000
31               0000 0000 0000 0000 0000 0000 0001 1111
e.hash & 31      0000 0000 0000 0000 0000 0000 0001 1001 => 扩容后的最终hash值，比原来增加16
```

分析一下`e.hash & oldCap`这一行，因为容量都是2的整数次幂，反映在二进制数上，只有1位是1，其他位都是0，而因为扩容后容量为2倍，新容量的二进制数只是把原来的那个1左移了一位。拿16和32来讲：

16  0001 0000  =>  旧容量

15  000<font color=#FF0000>0</font> 1111  =>  拿来计算最终hash的，即容量 - 1

32  0010 0000  =>  新容量

31  000<font color=#FF0000>1</font> 1111  =>  拿来计算最终hash的，即容量 - 1

就拿“拿来计算最终hash的”这一行看，除了红色的那一位，其他位旧的一样。

对`e.hash`来说，最终的hash计算值和原来是否一样，只由这一位是0还是1决定：

```
oldCap = 0001 0000
e.hash = ***0 **** => (e.hash & oldCap) == 0，新旧结果相同
e.hash = ***1 **** => (e.hash & oldCap) != 0，新旧结果相差 0001 0000，即oldCap大小
```

至此结论得证：

```java
((e.hash & oldCap) == 0) => newTab[j]
((e.hash & oldCap) != 0) => newTab[j + oldCap]
```

如果`(e.hash & oldCap) == 0`，数组下标不变，否则数组下标增加oldCap，判断条件用得非常巧妙。


